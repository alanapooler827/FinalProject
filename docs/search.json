[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Introduction\nThe data used in this project comes from the 2015 Behavioral Risk Factor Surveillance System report conducted by the CDC. View the data set on Kaggle.\nThe data set contains 22 variables. The variable ‘Diabetes_binary’ (diabetes or no diabetes) will be used as the response variable for modeling. This leaves 21 variables as potential predictors, which include information like whether or not the subject has high blood pressure, BMI, age, general health rating (self-assessed), and more. The cleaned data set from Kaggle contains 253,680 survey responses.\nWe will first explore the data and investigate the relationships between variables to get a sense of what variables could be useful for modeling. Then, we will build two models to predict the Diabetes_binary variable using a selection of the 21 predictor variables. We will be building a classification tree and a random forest model and evaluating the predictions from each to determine the best model.\n\n\nData Preparation\nImport libraries\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nRead in data\n\ndf &lt;- read_csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# view first few rows of data\nhead(df)\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1               0      1        1         1    40      1      0\n2               0      0        0         0    25      1      0\n3               0      1        1         1    28      0      0\n4               0      1        0         1    27      0      0\n5               0      1        1         1    24      0      0\n6               0      1        1         1    25      1      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nCheck for missing values\nNo missing values in any column\n\nsum_na &lt;- function(column){\n sum(is.na(column))\n}\n\ndf |&gt; summarize(across(everything(), sum_na))\n\n# A tibble: 1 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;int&gt;  &lt;int&gt;    &lt;int&gt;     &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n1               0      0        0         0     0      0      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;int&gt;, PhysActivity &lt;int&gt;,\n#   Fruits &lt;int&gt;, Veggies &lt;int&gt;, HvyAlcoholConsump &lt;int&gt;, AnyHealthcare &lt;int&gt;,\n#   NoDocbcCost &lt;int&gt;, GenHlth &lt;int&gt;, MentHlth &lt;int&gt;, PhysHlth &lt;int&gt;,\n#   DiffWalk &lt;int&gt;, Sex &lt;int&gt;, Age &lt;int&gt;, Education &lt;int&gt;, Income &lt;int&gt;\n\n\nView column types\nAll of the variables are numeric, but most of them are categorical variables encoded as numbers, so we will need to change those\n\nsapply(df, class)\n\n     Diabetes_binary               HighBP             HighChol \n           \"numeric\"            \"numeric\"            \"numeric\" \n           CholCheck                  BMI               Smoker \n           \"numeric\"            \"numeric\"            \"numeric\" \n              Stroke HeartDiseaseorAttack         PhysActivity \n           \"numeric\"            \"numeric\"            \"numeric\" \n              Fruits              Veggies    HvyAlcoholConsump \n           \"numeric\"            \"numeric\"            \"numeric\" \n       AnyHealthcare          NoDocbcCost              GenHlth \n           \"numeric\"            \"numeric\"            \"numeric\" \n            MentHlth             PhysHlth             DiffWalk \n           \"numeric\"            \"numeric\"            \"numeric\" \n                 Sex                  Age            Education \n           \"numeric\"            \"numeric\"            \"numeric\" \n              Income \n           \"numeric\" \n\n\nLook at unique values of each variable to see which ones should be converted into factors\n\nsapply(df, table)\n\n$Diabetes_binary\n\n     0      1 \n218334  35346 \n\n$HighBP\n\n     0      1 \n144851 108829 \n\n$HighChol\n\n     0      1 \n146089 107591 \n\n$CholCheck\n\n     0      1 \n  9470 244210 \n\n$BMI\n\n   12    13    14    15    16    17    18    19    20    21    22    23    24 \n    6    21    41   132   348   776  1803  3968  6327  9855 13643 15610 19550 \n   25    26    27    28    29    30    31    32    33    34    35    36    37 \n17146 20562 24606 16545 14890 14573 12275 10474  8948  7181  5575  4633  4147 \n   38    39    40    41    42    43    44    45    46    47    48    49    50 \n 3397  2911  2258  1659  1639  1500  1043   819   750   622   484   416   372 \n   51    52    53    54    55    56    57    58    59    60    61    62    63 \n  253   215   237   113   169   109    86    71    54    63    35    43    34 \n   64    65    66    67    68    69    70    71    72    73    74    75    76 \n   24    19    13    15    14     9    15    49    14    47    16    52     3 \n   77    78    79    80    81    82    83    84    85    86    87    88    89 \n   55     1    66     2    49    37     2    44     1     1    61     2    28 \n   90    91    92    95    96    98 \n    1     1    32    12     1     7 \n\n$Smoker\n\n     0      1 \n141257 112423 \n\n$Stroke\n\n     0      1 \n243388  10292 \n\n$HeartDiseaseorAttack\n\n     0      1 \n229787  23893 \n\n$PhysActivity\n\n     0      1 \n 61760 191920 \n\n$Fruits\n\n     0      1 \n 92782 160898 \n\n$Veggies\n\n     0      1 \n 47839 205841 \n\n$HvyAlcoholConsump\n\n     0      1 \n239424  14256 \n\n$AnyHealthcare\n\n     0      1 \n 12417 241263 \n\n$NoDocbcCost\n\n     0      1 \n232326  21354 \n\n$GenHlth\n\n    1     2     3     4     5 \n45299 89084 75646 31570 12081 \n\n$MentHlth\n\n     0      1      2      3      4      5      6      7      8      9     10 \n175680   8538  13054   7381   3789   9030    988   3100    639     91   6373 \n    11     12     13     14     15     16     17     18     19     20     21 \n    41    398     41   1167   5505     88     54     97     16   3364    227 \n    22     23     24     25     26     27     28     29     30 \n    63     38     33   1188     45     79    327    158  12088 \n\n$PhysHlth\n\n     0      1      2      3      4      5      6      7      8      9     10 \n160052  11388  14764   8495   4542   7622   1330   4538    809    179   5595 \n    11     12     13     14     15     16     17     18     19     20     21 \n    60    578     68   2587   4916    112     96    152     22   3273    663 \n    22     23     24     25     26     27     28     29     30 \n    70     56     72   1336     69     99    522    215  19400 \n\n$DiffWalk\n\n     0      1 \n211005  42675 \n\n$Sex\n\n     0      1 \n141974 111706 \n\n$Age\n\n    1     2     3     4     5     6     7     8     9    10    11    12    13 \n 5700  7598 11123 13823 16157 19819 26314 30832 33244 32194 23533 15980 17363 \n\n$Education\n\n     1      2      3      4      5      6 \n   174   4043   9478  62750  69910 107325 \n\n$Income\n\n    1     2     3     4     5     6     7     8 \n 9811 11783 15994 20135 25883 36470 43219 90385 \n\n\nConvert columns to factors where appropriate\n\n# specify columns to skip\nskip_convert &lt;- c('BMI', 'MentHlth', 'PhysHlth')\n\n# convert all other columns to factors\ndf &lt;- df |&gt;\n  mutate(across(-all_of(skip_convert), as.factor))\n\nRecode factor levels for better interpretability\nFirst recode all variables that have levels of Yes/No\n\n# skip variables that are not factors or do not have levels of yes/no \nskip_recode &lt;- c('BMI', 'GenHlth', 'MentHlth', 'PhysHlth',\n                 'Sex', 'Age', 'Education', 'Income')\n\nlvl_map &lt;- c(\"0\" = \"No\", \"1\" = \"Yes\")\n\ndf &lt;- df |&gt;\n  mutate(across(-all_of(skip_recode), ~ recode(.x, !!!lvl_map)))\n\nRecode remaining variables\n\ndf &lt;- df |&gt;\n  mutate(\n    GenHlth = fct_recode(\n      GenHlth,\n      'Excellent' = '1',\n      'Very Good' = '2',\n      'Good' = '3',\n      'Fair' = '4',\n      'Poor' = '5'\n    ),\n    Sex = fct_recode(\n      Sex,\n      'Female' = '0',\n      'Male' = '1'\n    ),\n    Age = fct_recode(\n      Age,\n      '18-24' = '1',\n      '25-29' = '2',\n      '30-34' = '3',\n      '35-39' = '4',\n      '40-44' = '5',\n      '45-49' = '6',\n      '50-54' = '7',\n      '55-59' = '8',\n      '60-64' = '9',\n      '65-69' = '10',\n      '70-74' = '11',\n      '75-79' = '12',\n      '80+' = '13'\n      ),\n    Education = fct_recode(\n      Education,\n      'None' = '1',\n      'Elementary School' = '2',\n      'Some High School' = '3',\n      'High School' = '4',\n      'Some College' = '5',\n      'College Graduate' = '6',\n      ),\n    Income = fct_recode(\n      Income,\n      \"Less than $10k\" = \"1\",\n      \"$10k to &lt; $15k\" = \"2\",\n      \"$15k to &lt; $20k\" = \"3\",\n      \"$20k to &lt; $25k\" = \"4\",\n      \"$25k to &lt; $35k\" = \"5\",\n      \"$35k to &lt; $50k\" = \"6\",\n      \"$50k to &lt; $75k\" = \"7\",\n      \"$75k or more\" = \"8\"\n      ),\n    )\n\n\n\nData Exploration\nNow we will look at some graphical and numerical summaries.\nNumber of participants without diabetes vs with diabetes\nThe data is very imbalanced, most participants do not have diabetes.\n\nggplot(df, aes(x = Diabetes_binary)) +\n  geom_bar(fill = 'deepskyblue4') +\n  theme_minimal()\n\n\n\n\n\n\n\n\nTwo-way contingency tables for Diabetes Status by all other categorical variables\nWe want to identify a subset of variables that may be useful predictors for Diabetes_binary, and comparing diabetes prevalence across the levels of each variable can give us an initial idea.\nWe can expect to that the proportions for participants without diabetes will be higher overall since there is a much larger number of those participants overall.\nA pattern that sticks out is that the proportion of participants with diabetes increase with age until ages 75+, when the proportion decreases.\nAnother pattern is that participants without diabetes have higher proportions for exercising, having health care coverage, eating fruits and veggies, no heart issues, and no heavy alcohol consumption. Some of these may be helpful predictor variables for modeling.\n\ncat_vars &lt;- names(df)[sapply(df, is.factor)]\n# remove Diabetes_binary from the list so we don't two way table with itself\ncat_vars &lt;- setdiff(cat_vars, \"Diabetes_binary\")\n\nfor (v in cat_vars) {\n  cat(\"\\n\")\n  cat(\"Diabetes_binary by\", v, \"\\n\")\n  print(round(prop.table(table(df$Diabetes_binary, df[[v]])), 3))\n}\n\n\nDiabetes_binary by HighBP \n     \n         No   Yes\n  No  0.537 0.324\n  Yes 0.034 0.105\n\nDiabetes_binary by HighChol \n     \n         No   Yes\n  No  0.530 0.331\n  Yes 0.046 0.093\n\nDiabetes_binary by CholCheck \n     \n         No   Yes\n  No  0.036 0.824\n  Yes 0.001 0.138\n\nDiabetes_binary by Smoker \n     \n         No   Yes\n  No  0.490 0.371\n  Yes 0.067 0.072\n\nDiabetes_binary by Stroke \n     \n         No   Yes\n  No  0.833 0.028\n  Yes 0.126 0.013\n\nDiabetes_binary by HeartDiseaseorAttack \n     \n         No   Yes\n  No  0.798 0.063\n  Yes 0.108 0.031\n\nDiabetes_binary by PhysActivity \n     \n         No   Yes\n  No  0.192 0.669\n  Yes 0.051 0.088\n\nDiabetes_binary by Fruits \n     \n         No   Yes\n  No  0.308 0.553\n  Yes 0.058 0.082\n\nDiabetes_binary by Veggies \n     \n         No   Yes\n  No  0.155 0.706\n  Yes 0.034 0.105\n\nDiabetes_binary by HvyAlcoholConsump \n     \n         No   Yes\n  No  0.808 0.053\n  Yes 0.136 0.003\n\nDiabetes_binary by AnyHealthcare \n     \n         No   Yes\n  No  0.043 0.817\n  Yes 0.006 0.134\n\nDiabetes_binary by NoDocbcCost \n     \n         No   Yes\n  No  0.791 0.069\n  Yes 0.125 0.015\n\nDiabetes_binary by GenHlth \n     \n      Excellent Very Good  Good  Fair  Poor\n  No      0.174     0.326 0.245 0.086 0.030\n  Yes     0.004     0.025 0.053 0.039 0.018\n\nDiabetes_binary by DiffWalk \n     \n         No   Yes\n  No  0.744 0.117\n  Yes 0.088 0.052\n\nDiabetes_binary by Sex \n     \n      Female  Male\n  No   0.487 0.374\n  Yes  0.073 0.067\n\nDiabetes_binary by Age \n     \n      18-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79\n  No  0.022 0.029 0.043 0.052 0.060 0.071 0.092 0.105 0.108 0.101 0.073 0.050\n  Yes 0.000 0.001 0.001 0.002 0.004 0.007 0.012 0.017 0.023 0.026 0.020 0.013\n     \n        80+\n  No  0.056\n  Yes 0.013\n\nDiabetes_binary by Education \n     \n       None Elementary School Some High School High School Some College\n  No  0.001             0.011            0.028       0.204        0.235\n  Yes 0.000             0.005            0.009       0.044        0.041\n     \n      College Graduate\n  No             0.382\n  Yes            0.041\n\nDiabetes_binary by Income \n     \n      Less than $10k $10k to &lt; $15k $15k to &lt; $20k $20k to &lt; $25k\n  No           0.029          0.034          0.049          0.063\n  Yes          0.009          0.012          0.014          0.016\n     \n      $25k to &lt; $35k $35k to &lt; $50k $50k to &lt; $75k $75k or more\n  No           0.084          0.123          0.150        0.328\n  Yes          0.018          0.021          0.021        0.028\n\n\nBox Plot of BMI vs Diabetes Status\nNot as much difference between the groups of diabetes status as I expected. This may not be the most userful variable to use as a predictor in the models.\n\nggplot(df, aes(x = Diabetes_binary, y = BMI)) +\n  geom_boxplot(fill = \"deepskyblue4\") +\n  labs(x = \"Diabetes Status\",\n       y = \"BMI\",\n       title = \"BMI Distribution by Diabetes Status\")\n\n\n\n\n\n\n\n\nDiabetes status by Age\nIn the no diabetes group, age 60-64 has the most subjects, whereas the diabetes group has the most subjects in the 65-69 age range.\n\nggplot(df, aes(x = Diabetes_binary, fill = Age)) +\n  geom_bar(position='dodge') +\n  labs(x = 'Diabetes Status',\n       title = 'Diabetes Status by Sex')\n\n\n\n\n\n\n\n\nDiabetes Status by General Health Rating\nIn the no diabetes group, most subjects rated their general health as ‘very good’, whereas most of the subjects in the diabetes group rated their health as ‘good; or ’fair’.\n\nggplot(df, aes(x = Diabetes_binary, fill = GenHlth)) +\n  geom_bar(position='dodge') +\n  labs(x = 'Diabetes Status',\n       title = 'Diabetes Status by General Health Rating')\n\n\n\n\n\n\n\n\nDiabetes Status grouped by High Blood Pressure\nThere is a clear relationship between HighBP and Diabetes_binary, with more people in the Diabetes group having high blood pressure. This could be a useful predictor variable for modeling.\n\nggplot(df, aes(x = Diabetes_binary, fill = HighBP)) +\n  geom_bar(position='dodge') +\n  labs(x = 'Diabetes Status',\n       title = 'Diabetes Status by High Blood Pressure (Yes/No)')\n\n\n\n\n\n\n\n\nDiabetes Status grouped by High Cholesterol\nThis plot is almost identical to the Diabetes status by HighBP plot. The number of subjects with high cholesterol is much lower than the number of subjects without high cholesterol in the no diabetes group, and vice versa for the diabetes group.\n\nggplot(df, aes(x = Diabetes_binary, fill = HighChol)) +\n  geom_bar(position='dodge') +\n  labs(x = 'Diabetes Status',\n       title = 'Diabetes Status by High Cholesterol (Yes/No)')\n\n\n\n\n\n\n\n\nDistributions of PhysHlth and MentHlth\nThe distributions are almost identical, both are heavily skewed to the right- most subjects had no days of injury/illness or poor mental health in the last 30 days.\n\nggplot(df, aes(x = PhysHlth)) +\n  geom_histogram(binwidth = 5, fill = \"deepskyblue4\") +\n  labs(x = '# of Days Physically Injured/Ill in Past 30 Days',\n       title = 'Distribution of Physical Health')\n\n\n\n\n\n\n\nggplot(df, aes(x = MentHlth)) +\n  geom_histogram(binwidth = 5, fill = \"deepskyblue4\") +\n  labs(x = '# of Days of Poor Mental Health in Past 30 Days',\n       title = 'Distribution of Physical Health')\n\n\n\n\n\n\n\n\nClick here to Visit the Modeling Page"
  },
  {
    "objectID": "EDA.html#quarto",
    "href": "EDA.html#quarto",
    "title": "EDA",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "EDA.html#running-code",
    "href": "EDA.html#running-code",
    "title": "EDA",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "In this section, we will be creating two predictive models using the 2015 Behavioral Risk Factor Surveillance System report data. The goal is to use the predictor variables in the data set to predict the variable Diabetes_binary, which indicates whether or not each subject has diabetes.\nWe will build a classification tree and a random forest model and evaluate both to determine which model performs the best at predicting the variable Diabetes_binary."
  },
  {
    "objectID": "Modeling.html#quarto",
    "href": "Modeling.html#quarto",
    "title": "Modeling",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Modeling.html#running-code",
    "href": "Modeling.html#running-code",
    "title": "Modeling",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Modeling",
    "section": "",
    "text": "In this section, we will be creating two predictive models using the 2015 Behavioral Risk Factor Surveillance System report data. The goal is to use the predictor variables in the data set to predict the variable Diabetes_binary, which indicates whether or not each subject has diabetes.\nWe will build a classification tree and a random forest model and evaluate both to determine which model performs the best at predicting the variable Diabetes_binary."
  },
  {
    "objectID": "Modeling.html#data-preparation",
    "href": "Modeling.html#data-preparation",
    "title": "Modeling",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n✔ broom        1.0.9     ✔ rsample      1.3.1\n✔ dials        1.4.2     ✔ tailor       0.1.0\n✔ infer        1.0.9     ✔ tune         2.0.1\n✔ modeldata    1.5.1     ✔ workflows    1.3.0\n✔ parsnip      1.3.3     ✔ workflowsets 1.1.1\n✔ recipes      1.3.1     ✔ yardstick    1.3.2\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(ggplot2)\nlibrary(future)\n\n# import function to load and clean the data set\nsource(\"data/load_clean_data.R\")\n\n# suppress scientific notation\noptions(scipen=999)\n\n# Use 10 cores\nplan(multisession, workers = 10)\n\nWarning in checkNumberOfLocalWorkers(workers): Careful, you are setting up 10\nlocalhost parallel workers with only 8 CPU cores available for this R process\n(per 'system'), which could result in a 125% load. The soft limit is set to\n100%. Overusing the CPUs has negative impact on the current R process, but also\non all other processes of yours and others running on the same machine. See\nhelp(\"parallelly.maxWorkers.localhost\", package = \"parallelly\") for further\nexplanations and how to override the soft limit that triggered this warning\n\n\nImport cleaned data\n\ndf &lt;- load_clean_data()\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# view first few rows of data\nhead(df)\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n  &lt;fct&gt;           &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt; \n1 No              Yes    Yes      Yes          40 Yes    No    \n2 No              No     No       No           25 Yes    No    \n3 No              Yes    Yes      Yes          28 No     No    \n4 No              Yes    No       Yes          27 No     No    \n5 No              Yes    Yes      Yes          24 No     No    \n6 No              Yes    Yes      Yes          25 Yes    No    \n# ℹ 15 more variables: HeartDiseaseorAttack &lt;fct&gt;, PhysActivity &lt;fct&gt;,\n#   Fruits &lt;fct&gt;, Veggies &lt;fct&gt;, HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;,\n#   NoDocbcCost &lt;fct&gt;, GenHlth &lt;fct&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;fct&gt;, Education &lt;fct&gt;, Income &lt;fct&gt;\n\n\nSplit data into training and test sets\nSet seed for reproducibility\n\nset.seed(42)\n\nSplit the data using 70% for the training set and 30% for the test set.\n\n# put 70% of the data in the training set\ndata_split &lt;- initial_split(df, prop = .70)\n\n# create data frames for the two sets\ntrain &lt;- training(data_split)\ntest &lt;- testing(data_split)\n\nCreate 5 fold cross validation split on the training data\n\ncv_fold &lt;- vfold_cv(train, 5)\n\nCreate recipes\nThe subset of variables used in recipe 2 were chosen by fitting the model with all 21 predictor variables and looking at variable importance.\n\n# recipe using all 21 predictor variables\nrec &lt;- recipe(Diabetes_binary ~ ., data = train)\n\n# recipe using subset of predictor variables\nrec2 &lt;- recipe(Diabetes_binary ~ HighBP + GenHlth + HighChol +\n                 Age + BMI + PhysHlth + DiffWalk,\n               data = train)"
  },
  {
    "objectID": "Modeling.html#classification-tree",
    "href": "Modeling.html#classification-tree",
    "title": "Modeling",
    "section": "Classification Tree",
    "text": "Classification Tree\nA classification tree is a type of predictive model used when the response variable is categorical, like Diabetes_binary. It works by splitting the predictor space up into regions, making a prediction based on which bin an observation ends up in, and then using the most prevalent class in a bin as the prediction. Classification trees are flexible and easy to interpret.\nCreate classification tree model instance and workflow\nSet cost_complexity = tune() to find the optimal value for that parameter.\n\ntree_spec &lt;- decision_tree(tree_depth = 8,\n                           min_n = 2,\n                           cost_complexity = tune()) |&gt;\n  set_engine('rpart') |&gt;\n  set_mode('classification')\n\n# workflow\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(rec2) |&gt;\n  add_model(tree_spec)\n\nFit the workflow on CV folds\nTry 5 values of the tuning parameter cost_complexity\n\ntree_fit &lt;- tree_wkf |&gt; \n  tune_grid(resamples = cv_fold,\n            grid = grid_regular(cost_complexity(),\n                                levels = 5),\n            metrics = metric_set(mn_log_loss, accuracy))\n\n# view metrics for each fold\ntree_fit |&gt;\n  collect_metrics(type = 'wide') |&gt;\n  arrange(mn_log_loss, accuracy)\n\n# A tibble: 5 × 4\n  cost_complexity .config         accuracy mn_log_loss\n            &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;       &lt;dbl&gt;\n1    0.0000000001 pre0_mod1_post0    0.864       0.332\n2    0.0000000178 pre0_mod2_post0    0.864       0.332\n3    0.00000316   pre0_mod3_post0    0.864       0.332\n4    0.000562     pre0_mod4_post0    0.865       0.356\n5    0.1          pre0_mod5_post0    0.861       0.404\n\n\nSelect the best model based on log loss\n\n# choose the best model based on log loss\nbest_tree &lt;- tree_fit |&gt;\n  select_best(metric = 'mn_log_loss')\nbest_tree\n\n# A tibble: 1 × 2\n  cost_complexity .config        \n            &lt;dbl&gt; &lt;chr&gt;          \n1    0.0000000001 pre0_mod1_post0"
  },
  {
    "objectID": "Modeling.html#random-forest",
    "href": "Modeling.html#random-forest",
    "title": "Modeling",
    "section": "Random Forest",
    "text": "Random Forest\nA random forest model is a type of ensemble model. It uses bootstrap sampling to create several smaller data sets from the original data set, and then fits a tree on each of those samples. Instead of using all predictors for every model, each model uses a different random subset of predictors. Final predictions are created by using the most prevalent prediction made by each tree.\nUsing several trees to make predictions instead of a single tree, as a classification tree does, can improve prediction accuracy.\nCreate Random Forest model instance and workflow\nSet mtry = tune() to find the optimal value for that parameter\nUsing all 21 predictors results in better metrics than selecting a subset of predictors based on variable importance, so we will use the first recipe for this model\n\nrf_spec &lt;- \n  rand_forest(mtry = tune(),\n              min_n = 40,\n              trees = 100) |&gt;\n  set_engine('ranger') |&gt;\n  set_mode('classification')\n\nrf_wkf &lt;- workflow() |&gt;\n  add_recipe(rec) |&gt;\n  add_model(rf_spec)\n\nFit model to CV folds and view metrics\n\nrf_fit &lt;- rf_wkf |&gt;\n  tune_grid(\n    resamples = cv_fold,\n    grid = 5,\n    metrics = metric_set(mn_log_loss, accuracy))\n\ni Creating pre-processing data to finalize 1 unknown parameter: \"mtry\"\n\nrf_fit |&gt;\n  collect_metrics(type = 'wide') |&gt;\n  arrange(mn_log_loss, accuracy)\n\n# A tibble: 5 × 4\n   mtry .config         accuracy mn_log_loss\n  &lt;int&gt; &lt;chr&gt;              &lt;dbl&gt;       &lt;dbl&gt;\n1     6 pre0_mod2_post0    0.865       0.320\n2    11 pre0_mod3_post0    0.865       0.329\n3    16 pre0_mod4_post0    0.865       0.334\n4    21 pre0_mod5_post0    0.864       0.339\n5     1 pre0_mod1_post0    0.861       0.343\n\n\nSelect the best model based on log loss\n\n# choose the best model based on log loss\nbest_rf &lt;- rf_fit |&gt;\n  select_best(metric = 'mn_log_loss')\nbest_rf\n\n# A tibble: 1 × 2\n   mtry .config        \n  &lt;int&gt; &lt;chr&gt;          \n1     6 pre0_mod2_post0"
  },
  {
    "objectID": "Modeling.html#model-comparison",
    "href": "Modeling.html#model-comparison",
    "title": "Modeling",
    "section": "Model Comparison",
    "text": "Model Comparison\nFit each model on the test set\nClassification Tree\n\ntree_final &lt;- tree_wkf |&gt;\n  finalize_workflow(best_tree) |&gt;\n  last_fit(data_split, metrics = metric_set(mn_log_loss, accuracy))\n\ntree_final |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 accuracy    binary         0.866 pre0_mod0_post0\n2 mn_log_loss binary         0.332 pre0_mod0_post0\n\n\nRandom Forest Model\n\nrf_final &lt;- rf_wkf |&gt;\n  finalize_workflow(best_rf) |&gt;\n  last_fit(data_split, metrics = metric_set(mn_log_loss, accuracy))\n\nrf_final |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 accuracy    binary         0.867 pre0_mod0_post0\n2 mn_log_loss binary         0.318 pre0_mod0_post0\n\n\nCompare metrics for each model\nThe random forest model has a very slightly higher accuracy and lower log loss than the classification tree model, so random forest is crowned the winner!\n\nrbind(\n  tree_final |&gt;\n    collect_metrics(type = 'wide') |&gt; \n    mutate(Model = 'TREE', .before = 'mn_log_loss'),\n  rf_final |&gt;\n    collect_metrics(type = 'wide') |&gt; \n    mutate(Model = 'RF', .before = 'mn_log_loss')\n) |&gt;\n  arrange(mn_log_loss, accuracy)\n\n# A tibble: 2 × 4\n  .config         accuracy Model mn_log_loss\n  &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n1 pre0_mod0_post0    0.867 RF          0.318\n2 pre0_mod0_post0    0.866 TREE        0.332"
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "The data used in this project comes from the 2015 Behavioral Risk Factor Surveillance System report conducted by the CDC. View the data set on Kaggle.\nThe data set contains 22 variables. The variable ‘Diabetes_binary’ will be used as the response variable and has the values 0 for no diabetes and 1 for prediabetes or diabetes. This leaves 21 variables as potential predictors, which include information like whether or not the subject has high blood pressure, BMI, age, general health rating (self-assessed), and more. The cleaned data set from Kaggle contains 253,680 survey responses\nWe will first explore the data and investigate the relationships between variables to get a sense of what variables could be useful for modeling. Then, we will build two models to predict the Diabetes_binary variable using a selection of the 21 predictor variables. We will be building a classification tree and a random forest model and evaluating the predictions from each to determine the best model."
  },
  {
    "objectID": "EDA.html#data-preparation",
    "href": "EDA.html#data-preparation",
    "title": "Exploratory Data Analysis",
    "section": "Data Preparation",
    "text": "Data Preparation\nImport libraries\nRead in data\n\ndf &lt;- read_csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# view first few rows of data\nhead(df)\n\n# A tibble: 6 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1               0      1        1         1    40      1      0\n2               0      0        0         0    25      1      0\n3               0      1        1         1    28      0      0\n4               0      1        0         1    27      0      0\n5               0      1        1         1    24      0      0\n6               0      1        1         1    25      1      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;\n\n\nCheck for missing values\nNo missing values in any column\n\nsum_na &lt;- function(column){\n sum(is.na(column))\n}\n\ndf |&gt; summarize(across(everything(), sum_na))\n\n# A tibble: 1 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;int&gt;  &lt;int&gt;    &lt;int&gt;     &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n1               0      0        0         0     0      0      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;int&gt;, PhysActivity &lt;int&gt;,\n#   Fruits &lt;int&gt;, Veggies &lt;int&gt;, HvyAlcoholConsump &lt;int&gt;, AnyHealthcare &lt;int&gt;,\n#   NoDocbcCost &lt;int&gt;, GenHlth &lt;int&gt;, MentHlth &lt;int&gt;, PhysHlth &lt;int&gt;,\n#   DiffWalk &lt;int&gt;, Sex &lt;int&gt;, Age &lt;int&gt;, Education &lt;int&gt;, Income &lt;int&gt;\n\n\nView column types\nAll of the variables are numeric, but most of them are categorical variables encoded as numbers, so we will need to change those\n\nsapply(df, class)\n\n     Diabetes_binary               HighBP             HighChol \n           \"numeric\"            \"numeric\"            \"numeric\" \n           CholCheck                  BMI               Smoker \n           \"numeric\"            \"numeric\"            \"numeric\" \n              Stroke HeartDiseaseorAttack         PhysActivity \n           \"numeric\"            \"numeric\"            \"numeric\" \n              Fruits              Veggies    HvyAlcoholConsump \n           \"numeric\"            \"numeric\"            \"numeric\" \n       AnyHealthcare          NoDocbcCost              GenHlth \n           \"numeric\"            \"numeric\"            \"numeric\" \n            MentHlth             PhysHlth             DiffWalk \n           \"numeric\"            \"numeric\"            \"numeric\" \n                 Sex                  Age            Education \n           \"numeric\"            \"numeric\"            \"numeric\" \n              Income \n           \"numeric\" \n\n\nLook at unique values of each variable to see which ones should be converted into factors\n\nsapply(df, table)\n\n$Diabetes_binary\n\n     0      1 \n218334  35346 \n\n$HighBP\n\n     0      1 \n144851 108829 \n\n$HighChol\n\n     0      1 \n146089 107591 \n\n$CholCheck\n\n     0      1 \n  9470 244210 \n\n$BMI\n\n   12    13    14    15    16    17    18    19    20    21    22    23    24 \n    6    21    41   132   348   776  1803  3968  6327  9855 13643 15610 19550 \n   25    26    27    28    29    30    31    32    33    34    35    36    37 \n17146 20562 24606 16545 14890 14573 12275 10474  8948  7181  5575  4633  4147 \n   38    39    40    41    42    43    44    45    46    47    48    49    50 \n 3397  2911  2258  1659  1639  1500  1043   819   750   622   484   416   372 \n   51    52    53    54    55    56    57    58    59    60    61    62    63 \n  253   215   237   113   169   109    86    71    54    63    35    43    34 \n   64    65    66    67    68    69    70    71    72    73    74    75    76 \n   24    19    13    15    14     9    15    49    14    47    16    52     3 \n   77    78    79    80    81    82    83    84    85    86    87    88    89 \n   55     1    66     2    49    37     2    44     1     1    61     2    28 \n   90    91    92    95    96    98 \n    1     1    32    12     1     7 \n\n$Smoker\n\n     0      1 \n141257 112423 \n\n$Stroke\n\n     0      1 \n243388  10292 \n\n$HeartDiseaseorAttack\n\n     0      1 \n229787  23893 \n\n$PhysActivity\n\n     0      1 \n 61760 191920 \n\n$Fruits\n\n     0      1 \n 92782 160898 \n\n$Veggies\n\n     0      1 \n 47839 205841 \n\n$HvyAlcoholConsump\n\n     0      1 \n239424  14256 \n\n$AnyHealthcare\n\n     0      1 \n 12417 241263 \n\n$NoDocbcCost\n\n     0      1 \n232326  21354 \n\n$GenHlth\n\n    1     2     3     4     5 \n45299 89084 75646 31570 12081 \n\n$MentHlth\n\n     0      1      2      3      4      5      6      7      8      9     10 \n175680   8538  13054   7381   3789   9030    988   3100    639     91   6373 \n    11     12     13     14     15     16     17     18     19     20     21 \n    41    398     41   1167   5505     88     54     97     16   3364    227 \n    22     23     24     25     26     27     28     29     30 \n    63     38     33   1188     45     79    327    158  12088 \n\n$PhysHlth\n\n     0      1      2      3      4      5      6      7      8      9     10 \n160052  11388  14764   8495   4542   7622   1330   4538    809    179   5595 \n    11     12     13     14     15     16     17     18     19     20     21 \n    60    578     68   2587   4916    112     96    152     22   3273    663 \n    22     23     24     25     26     27     28     29     30 \n    70     56     72   1336     69     99    522    215  19400 \n\n$DiffWalk\n\n     0      1 \n211005  42675 \n\n$Sex\n\n     0      1 \n141974 111706 \n\n$Age\n\n    1     2     3     4     5     6     7     8     9    10    11    12    13 \n 5700  7598 11123 13823 16157 19819 26314 30832 33244 32194 23533 15980 17363 \n\n$Education\n\n     1      2      3      4      5      6 \n   174   4043   9478  62750  69910 107325 \n\n$Income\n\n    1     2     3     4     5     6     7     8 \n 9811 11783 15994 20135 25883 36470 43219 90385 \n\n\nConvert columns to factors where appropriate\n\n# specify columns to skip\nskip_convert &lt;- c('BMI', 'MentHlth', 'PhysHlth')\n\n# convert all other columns to factors\ndf &lt;- df |&gt;\n  mutate(across(-all_of(skip_convert), as.factor))\n\nRecode factor levels for better interpretability\nFirst recode all variables that have levels of Yes/No\n\n# skip variables that are not factors or do not have levels of yes/no \nskip_recode &lt;- c('BMI', 'GenHlth', 'MentHlth', 'PhysHlth',\n                 'Sex', 'Age', 'Education', 'Income')\n\nlvl_map &lt;- c(\"0\" = \"No\", \"1\" = \"Yes\")\n\ndf &lt;- df |&gt;\n  mutate(across(-all_of(skip_recode), ~ recode(.x, !!!lvl_map)))\n\nRecode remaining variables\n\ndf &lt;- df |&gt;\n  mutate(\n    GenHlth = fct_recode(\n      GenHlth,\n      'Excellent' = '1',\n      'Very Good' = '2',\n      'Good' = '3',\n      'Fair' = '4',\n      'Poor' = '5'\n    ),\n    Sex = fct_recode(\n      Sex,\n      'Female' = '0',\n      'Male' = '1'\n    ),\n    Age = fct_recode(\n      Age,\n      '18-24' = '1',\n      '25-29' = '2',\n      '30-34' = '3',\n      '35-39' = '4',\n      '40-44' = '5',\n      '45-49' = '6',\n      '50-54' = '7',\n      '55-59' = '8',\n      '60-64' = '9',\n      '65-69' = '10',\n      '70-74' = '11',\n      '75-79' = '12',\n      '80+' = '13'\n      ),\n    Education = fct_recode(\n      Education,\n      'None' = '1',\n      'Elementary School' = '2',\n      'Some High School' = '3',\n      'High School' = '4',\n      'Some College' = '5',\n      'College Graduate' = '6',\n      ),\n    Income = fct_recode(\n      Income,\n      \"Less than $10k\" = \"1\",\n      \"$10k to &lt; $15k\" = \"2\",\n      \"$15k to &lt; $20k\" = \"3\",\n      \"$20k to &lt; $25k\" = \"4\",\n      \"$25k to &lt; $35k\" = \"5\",\n      \"$35k to &lt; $50k\" = \"6\",\n      \"$50k to &lt; $75k\" = \"7\",\n      \"$75k or more\" = \"8\"\n      ),\n    )"
  },
  {
    "objectID": "EDA.html#data-exploration",
    "href": "EDA.html#data-exploration",
    "title": "Exploratory Data Analysis",
    "section": "Data Exploration",
    "text": "Data Exploration\nNow we will look at some graphical and numerical summaries.\nNumber of participants without diabetes vs with prediabetes/diabetes\nThe data is very imbalanced, most participants do not have prediabetes/diabetes.\n\nggplot(df, aes(x = Diabetes_binary)) +\n  geom_bar(fill = 'deepskyblue4') +\n  theme_minimal()\n\n\n\n\n\n\n\n\nTwo-way contingency tables for Diabetes Status by all other categorical variables\nWe want to identify a subset of variables that may be useful predictors for Diabetes_binary, and comparing diabetes prevalence across the levels of each variable can give us an initial idea.\nWe can expect to that the proportions for participants without prediabetes/diabetes will be higher overall since there is a much larger number of those participants overall.\nA pattern that sticks out is that the proportion of participants with prediabetes/diabetes increase with age until ages 75+, when the proportion decreases.\nAnother pattern is that participants without diabetes have higher proportions for exercising, having health care coverage, eating fruits and veggies, no heart issues, and no heavy alcohol consumption. Some of these may be helpful predictor variables for modeling.\n\ncat_vars &lt;- names(df)[sapply(df, is.factor)]\n# remove Diabetes_binary from the list so we don't two way table with itself\ncat_vars &lt;- setdiff(cat_vars, \"Diabetes_binary\")\n\nfor (v in cat_vars) {\n  cat(\"\\n\")\n  cat(\"Diabetes_binary by\", v, \"\\n\")\n  print(round(prop.table(table(df$Diabetes_binary, df[[v]])), 3))\n}\n\n\nDiabetes_binary by HighBP \n     \n         No   Yes\n  No  0.537 0.324\n  Yes 0.034 0.105\n\nDiabetes_binary by HighChol \n     \n         No   Yes\n  No  0.530 0.331\n  Yes 0.046 0.093\n\nDiabetes_binary by CholCheck \n     \n         No   Yes\n  No  0.036 0.824\n  Yes 0.001 0.138\n\nDiabetes_binary by Smoker \n     \n         No   Yes\n  No  0.490 0.371\n  Yes 0.067 0.072\n\nDiabetes_binary by Stroke \n     \n         No   Yes\n  No  0.833 0.028\n  Yes 0.126 0.013\n\nDiabetes_binary by HeartDiseaseorAttack \n     \n         No   Yes\n  No  0.798 0.063\n  Yes 0.108 0.031\n\nDiabetes_binary by PhysActivity \n     \n         No   Yes\n  No  0.192 0.669\n  Yes 0.051 0.088\n\nDiabetes_binary by Fruits \n     \n         No   Yes\n  No  0.308 0.553\n  Yes 0.058 0.082\n\nDiabetes_binary by Veggies \n     \n         No   Yes\n  No  0.155 0.706\n  Yes 0.034 0.105\n\nDiabetes_binary by HvyAlcoholConsump \n     \n         No   Yes\n  No  0.808 0.053\n  Yes 0.136 0.003\n\nDiabetes_binary by AnyHealthcare \n     \n         No   Yes\n  No  0.043 0.817\n  Yes 0.006 0.134\n\nDiabetes_binary by NoDocbcCost \n     \n         No   Yes\n  No  0.791 0.069\n  Yes 0.125 0.015\n\nDiabetes_binary by GenHlth \n     \n      Excellent Very Good  Good  Fair  Poor\n  No      0.174     0.326 0.245 0.086 0.030\n  Yes     0.004     0.025 0.053 0.039 0.018\n\nDiabetes_binary by DiffWalk \n     \n         No   Yes\n  No  0.744 0.117\n  Yes 0.088 0.052\n\nDiabetes_binary by Sex \n     \n      Female  Male\n  No   0.487 0.374\n  Yes  0.073 0.067\n\nDiabetes_binary by Age \n     \n      18-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79\n  No  0.022 0.029 0.043 0.052 0.060 0.071 0.092 0.105 0.108 0.101 0.073 0.050\n  Yes 0.000 0.001 0.001 0.002 0.004 0.007 0.012 0.017 0.023 0.026 0.020 0.013\n     \n        80+\n  No  0.056\n  Yes 0.013\n\nDiabetes_binary by Education \n     \n       None Elementary School Some High School High School Some College\n  No  0.001             0.011            0.028       0.204        0.235\n  Yes 0.000             0.005            0.009       0.044        0.041\n     \n      College Graduate\n  No             0.382\n  Yes            0.041\n\nDiabetes_binary by Income \n     \n      Less than $10k $10k to &lt; $15k $15k to &lt; $20k $20k to &lt; $25k\n  No           0.029          0.034          0.049          0.063\n  Yes          0.009          0.012          0.014          0.016\n     \n      $25k to &lt; $35k $35k to &lt; $50k $50k to &lt; $75k $75k or more\n  No           0.084          0.123          0.150        0.328\n  Yes          0.018          0.021          0.021        0.028\n\n\nBox Plot of BMI vs Diabetes Status\nNot as much difference between the groups of diabetes status as I expected. This may not be the most userful variable to use as a predictor in the models.\n\nggplot(df, aes(x = Diabetes_binary, y = BMI)) +\n  geom_boxplot(fill = \"deepskyblue4\") +\n  labs(x = \"Diabetes Status\",\n       y = \"BMI\",\n       title = \"BMI Distribution by Diabetes Status\")\n\n\n\n\n\n\n\n\nDiabetes status by Age\nIn the no diabetes group, age 60-64 has the most subjects, whereas the prediabetes/diabetes group has the most subjects in the 65-69 age range.\n\nggplot(df, aes(x = Diabetes_binary, fill = Age)) +\n  geom_bar(position='dodge') +\n  labs(x = 'Diabetes Status',\n       title = 'Diabetes Status by Sex')\n\n\n\n\n\n\n\n\nDiabetes Status by General Health Rating\nIn the no diabetes group, most subjects rated their general health as ‘very good’, whereas most of the subjects in the diabetes group rated their health as ‘good; or ’fair’.\n\nggplot(df, aes(x = Diabetes_binary, fill = GenHlth)) +\n  geom_bar(position='dodge') +\n  labs(x = 'Diabetes Status',\n       title = 'Diabetes Status by General Health Rating')\n\n\n\n\n\n\n\n\nDiabetes Status grouped by High Blood Pressure\nThere is a clear relationship between HighBP and Diabetes_binary, with more people in the Diabetes group having high blood pressure. This could be a useful predictor variable for modeling.\n\nggplot(df, aes(x = Diabetes_binary, fill = HighBP)) +\n  geom_bar(position='dodge') +\n  labs(x = 'Diabetes Status',\n       title = 'Diabetes Status by High Blood Pressure (Yes/No)')\n\n\n\n\n\n\n\n\nDiabetes Status grouped by High Cholesterol\nThis plot is almost identical to the Diabetes status by HighBP plot. The number of subjects with high cholesterol is much lower than the number of subjects without high cholesterol in the no diabetes group, and vice versa for the diabetes group.\n\nggplot(df, aes(x = Diabetes_binary, fill = HighChol)) +\n  geom_bar(position='dodge') +\n  labs(x = 'Diabetes Status',\n       title = 'Diabetes Status by High Cholesterol (Yes/No)')\n\n\n\n\n\n\n\n\nDistributions of PhysHlth and MentHlth\nThe distributions are almost identical, both are heavily skewed to the right- most subjects had no days of injury/illness or poor mental health in the last 30 days.\n\nggplot(df, aes(x = PhysHlth)) +\n  geom_histogram(binwidth = 5, fill = \"deepskyblue4\") +\n  labs(x = '# of Days Physically Injured/Ill in Past 30 Days',\n       title = 'Distribution of Physical Health')\n\n\n\n\n\n\n\nggplot(df, aes(x = MentHlth)) +\n  geom_histogram(binwidth = 5, fill = \"deepskyblue4\") +\n  labs(x = '# of Days of Poor Mental Health in Past 30 Days',\n       title = 'Distribution of Physical Health')\n\n\n\n\n\n\n\n\nClick here to Visit the Modeling Page"
  }
]